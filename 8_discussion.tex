\section{Discussion}

\subsection{Theoretical analysis}
In this paper the significance measure is not used heuristically, as it is sometimes used in other literature.
The significance measure is an exact measure of the relative size of gaps when using the naive toolpathing method.
See \cref{naive_overfill_underfill}
Note also that contrary to some literature we don't remove bones from the skeleton, but leave it intact.
The final skeleton is still an exact and full feature descriptor.
In that sense our framework provides an exact solution space.

Note also that our method is robust against small perturbations in the input shape.
Although the skeleton might acquire extra bones, the significant portions of the skeleton remain similar and the output toolpaths change infinitesimally.

Our framework is also local.
The toolpathing around some section of the input polygons is independent of far away regions of the polygon.
This means the toolpathing is stable against large perturbations of the input shape in far away regions
and it also allows for some parallelism during the computation of the toolpaths.


\subsection{Computation time}
Algorithmic complexity is limited by the generation of the Voronoi Diagram, which is $O(n \log n)$, where $n$ is the number of vertices in the input shape.
The number of elements in the trapezoidation is linear in the number of elements in the VD
and all of the stages of our framework are also linear in the number of elements in the skeleton,
so the total running time of our algorithm is $O(n \log n)$.

From the experimental results shows in \cref{computime} we can see that both our framework and the naive method as implemented using Clipper have an expected running time of approximately $10^{-5} n \log n$ seconds.
The computation time is approximately five times the computation time of the naive method, which puts it in the same order of magnitude.




\subsection{Comparison of beading strategies}
\todo{Discussion of finding of Validation section}

The naive strategy and the single bead strategy are of little use to FDM printers, but they show the flexibility of our parametric system.

Naive method causes a lot of overfills and underfills.
This overpoweres any positive effect of perfectly homogeneous bead width.

The single bead strategy solves the underfill problem in regions where the model is more thin than the nozzle size.
However, the strategy doesn't deal with the remaining area.
In our visualization we print the outline of the remaining area which exposes an overextrusion problem.

The constant beading strategy effectively deals with all overfills and underfills, but at the cost of wildly differing bead widths.
For an input outline shape which contains both very small and very large features the algorithm produces bead widths which can fall outside of the range of manufacturable bead widths.

The center beading strategy effectively deals with overfill and underfill and produces bead widths which are the optimal bead width in all locations, but in the center the bead widths are within a factor 2 off from the optimal bead width, which is still quite a bit.

The distributed strategy greatly reduces the total underfill and overfill and severely limits the amount of beads with a width which differs greatly from an optimal width, but the toolpaths contain a lot of bends in transitioning areas.

The inward distributed beading strategy shows similar behavior to the distributed strategy, but large regions are less affected by the bends introduced because of transitioning.
This can be seen in \cref{applications_gear}.







